{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7c9b9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sumy in c:\\users\\91810\\appdata\\roaming\\python\\python311\\site-packages (0.11.0)\n",
      "Requirement already satisfied: docopt<0.7,>=0.6.1 in c:\\users\\91810\\appdata\\roaming\\python\\python311\\site-packages (from sumy) (0.6.2)\n",
      "Requirement already satisfied: breadability>=0.1.20 in c:\\users\\91810\\appdata\\roaming\\python\\python311\\site-packages (from sumy) (0.1.20)\n",
      "Requirement already satisfied: requests>=2.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sumy) (2.31.0)\n",
      "Requirement already satisfied: pycountry>=18.2.23 in c:\\users\\91810\\appdata\\roaming\\python\\python311\\site-packages (from sumy) (24.6.1)\n",
      "Requirement already satisfied: nltk>=3.0.2 in c:\\users\\91810\\appdata\\roaming\\python\\python311\\site-packages (from sumy) (3.9.1)\n",
      "Requirement already satisfied: chardet in c:\\programdata\\anaconda3\\lib\\site-packages (from breadability>=0.1.20->sumy) (4.0.0)\n",
      "Requirement already satisfied: lxml>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from breadability>=0.1.20->sumy) (4.9.3)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (2023.11.17)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk>=3.0.2->sumy) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\anaconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    }
   ],
   "source": [
    "!pip install sumy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1285ef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.parsers.html import HtmlParser\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "from sumy.summarizers.luhn import LuhnSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a26e352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lxml.html.clean in c:\\users\\91810\\appdata\\roaming\\python\\python311\\site-packages (0.4.1)\n",
      "Requirement already satisfied: lxml in c:\\programdata\\anaconda3\\lib\\site-packages (from lxml.html.clean) (4.9.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\anaconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml.html.clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e7eb72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "However, there is an enormous amount of non-annotated data available (including, among other things, the entire content of the World Wide Web), which can often make up for the worse efficiency if the algorithm used has a low enough time complexity to be practical.\n",
      "[ 14] This is increasingly important in medicine and healthcare, where NLP helps analyze notes and text in electronic health records that would otherwise be inaccessible for study when seeking to improve care[ 16] or protect patient privacy.\n",
      "Retrieved 5 December 2021.^ Yi, Chucai; Tian, Yingli(2012), \"Assistive Text Reading from Complex Background for Blind Persons\", Camera-Based Document Analysis and Recognition, Lecture Notes in Computer Science, vol.\n",
      "Advances in Neural Information Processing Systems.^ Kariampuzha, William; Alyea, Gioconda; Qu, Sue; Sanjak, Jaleal; Mathé, Ewy; Sid, Eric; Chatelaine, Haley; Yadaw, Arjun; Xu, Yanji; Zhu, Qian (2023).\n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.html import HtmlParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "\n",
    "LANGUAGE = \"english\"\n",
    "SENTENCE_COUNT = 4\n",
    "url = \"http://en.wikipedia.org/wiki/Natural_language_processing\"\n",
    "\n",
    "parser = HtmlParser.from_url(url, Tokenizer(LANGUAGE))\n",
    "summarizer = LsaSummarizer(Stemmer(LANGUAGE))\n",
    "summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "for sentence in summarizer(parser.document, SENTENCE_COUNT):\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd1a0297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c964dfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15– 28, CiteSeerX 10.1.1.668.869, doi: 10.1007/978-3-642-29364-1_2, ISBN 9783642293634^ a b\"Natural Language Processing (NLP) - A Complete Guide\".Retrieved 2024-05-05.^\"What is Natural Language Processing?\"Models of natural language understanding\".Natural Language Processing and Computational Linguistics: semantics, discourse, and applications, Volume 2.Machine Learning of Natural Language.\n"
     ]
    }
   ],
   "source": [
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.utils import get_stop_words\n",
    "summarizer_lex = LexRankSummarizer()\n",
    "summarizer_lex.stop_words = get_stop_words(\"english\")\n",
    "summary = summarizer_lex(parser.document,5)\n",
    "lex_summary = \"\"\n",
    "for sentence in summary:\n",
    "    lex_summary += str(sentence)\n",
    "print(lex_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17470bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
